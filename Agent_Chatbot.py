import os
import streamlit as st
from typing import List, Dict, Any
from pinecone import Pinecone
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_pinecone import PineconeVectorStore

# Pinecone ë° API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["openai_api_key"]
os.environ["PINECONE_API_KEY"] = st.secrets["pinecone_api_key"]

# Pinecone ì»¤ìŠ¤í…€ ë²¡í„° ìŠ¤í† ì–´
class ModifiedPineconeVectorStore(PineconeVectorStore):
    def __init__(self, index, embedding, text_key: str = "text", namespace: str = ""):
        super().__init__(index, embedding, text_key, namespace)
        self.index = index
        self._embedding = embedding
        self._text_key = text_key
        self._namespace = namespace

# Chatbot í”„ë¡¬í”„íŠ¸
chatbot_template = """
Question: {question}
Context: {context}
Answer:
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë©”íƒ€ë°ì´í„°ì˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
- ì£¼ì–´ì§„ ë¬¸ì„œì˜ ì¶œì²˜(source), í•µì‹¬ ë‚´ìš©(text), ê·¸ë¦¬ê³  ê´€ë ¨ëœ íƒœê·¸(tag_contents, tag_people, tag_company)ë¥¼ í™œìš©í•´ì„œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
- í•œêµ­ì–´ë¡œ ëŒ€í™”í˜• í†¤ìœ¼ë¡œ 2ì²œì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- í•´ë‹¹ ë‚´ìš© ë¬¸ë‹¨ì˜ ëì—ëŠ” ì¶œì²˜, ë°œí‘œì ë‚´ìš©ì„ ê¼­ í‘œì‹œí•´ì£¼ì„¸ìš”.
"""
chatbot_prompt = ChatPromptTemplate.from_template(chatbot_template)

def main():
    st.title("ğŸ“š Agent Conference Q&A Chatbot")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Pinecone ì´ˆê¸°í™”
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index_name = "aiconference"
    index = pc.Index(index_name)

    # OpenAI ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o")
    vectorstore = ModifiedPineconeVectorStore(
        index=index,
        embedding=OpenAIEmbeddings(model="text-embedding-ada-002"),
        text_key="text"
    )

    # ê²€ìƒ‰ í•„í„° ì„¤ì • í•¨ìˆ˜
    def create_retriever_with_filter(keywords: Dict[str, Any]) -> ModifiedPineconeVectorStore:
        """
        Pinecone retrieverì— í•„í„° ì¡°ê±´ì„ ì ìš©í•˜ëŠ” í•¨ìˆ˜.
        """
        filter_conditions = {}

        # í•„í„° ì¡°ê±´ ì¶”ê°€
        if keywords.get("tag_contents"):
            filter_conditions["tag_contents"] = {"$in": keywords["tag_contents"]}
        if keywords.get("tag_people"):
            filter_conditions["tag_people"] = {"$in": keywords["tag_people"]}
        if keywords.get("tag_company"):
            filter_conditions["tag_company"] = {"$in": keywords["tag_company"]}
        if keywords.get("source"):
            filter_conditions["source"] = {"$in": keywords["source"]}

        # ë””ë²„ê¹…: í•„í„° ì¡°ê±´ ì¶œë ¥
        st.write("ì ìš©ëœ í•„í„° ì¡°ê±´:", filter_conditions)

        # í•„í„° ì¡°ê±´ì´ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì„¤ì •
        return vectorstore.as_retriever(
            search_type='similarity',
            search_kwargs={
                "k": 10,
                "filter": filter_conditions if filter_conditions else None
            }
        )

    # ë¬¸ì„œ í¬ë§· í•¨ìˆ˜
    def format_docs(docs: List[Document]) -> str:
        formatted = []
        for doc in docs:
            source = doc.metadata.get('source', 'Unknown source')
            text = doc.page_content
            tags = ', '.join(
                f"{k}: {v}" for k, v in doc.metadata.items() if k.startswith("tag_")
            )
            formatted.append(f"ì¶œì²˜: {source}\níƒœê·¸: {tags}\në‚´ìš©: {text}")
        return "\n\n".join(formatted)

    # ë¬¸ì„œì™€ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ë‹µë³€ ìƒì„±
    def create_response(question: str, keywords: Dict[str, Any]) -> str:
        """
        ì§ˆë¬¸ê³¼ í•„í„° ì¡°ê±´ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±.
        """
        # ì§ˆë¬¸ ìœ íš¨ì„± ê²€ì‚¬
        if not isinstance(question, str) or not question.strip():
            return "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

        try:
            # í•„í„°ê°€ ì ìš©ëœ retriever ìƒì„±
            retriever = create_retriever_with_filter(keywords)

            # ë¬¸ì„œ ê²€ìƒ‰
            docs = retriever.invoke(question)
            if not docs:
                st.write("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”.")
                return "ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."

            # ë””ë²„ê¹…: ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© ì¶œë ¥
            st.write("ê²€ìƒ‰ëœ ë¬¸ì„œ:", docs)

            # ë¬¸ì„œ í¬ë§· ë° ê¸¸ì´ ì œí•œ ì ìš©
            context = format_docs(docs)
            max_length = 2000  # OpenAI API ì…ë ¥ ê¸¸ì´ ì œí•œ (ë¬¸ì ê¸°ì¤€)
            context = context[:max_length]

            # í”„ë¡¬í”„íŠ¸ ìƒì„± ë° LLM í˜¸ì¶œ
            prompt_input = {"question": question, "context": context}
            prompt = chatbot_prompt.invoke(prompt_input)
            llm_response = llm.invoke(prompt)
            return StrOutputParser().invoke(llm_response)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    # ì´ì „ ëŒ€í™” í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    with st.form("filter_form"):
        st.write("ì§ˆë¬¸ê³¼ í•¨ê»˜ í•„í„° ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš”:")
        question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
        tag_contents = st.text_input("íƒœê·¸ ë‚´ìš© (ì‰¼í‘œë¡œ êµ¬ë¶„)", "")
        tag_people = st.text_input("ê´€ë ¨ ì¸ë¬¼ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "")
        tag_company = st.text_input("ê´€ë ¨ íšŒì‚¬ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "")
        source = st.text_input("ì¶œì²˜ (ì‰¼í‘œë¡œ êµ¬ë¶„)", "")
        submitted = st.form_submit_button("ê²€ìƒ‰")

    if submitted and question:
        # í•„í„° í‚¤ì›Œë“œ ìƒì„±
        keywords = {
            "tag_contents": [tag.strip() for tag in tag_contents.split(",") if tag.strip()],
            "tag_people": [person.strip() for person in tag_people.split(",") if person.strip()],
            "tag_company": [company.strip() for company in tag_company.split(",") if company.strip()],
            "source": [src.strip() for src in source.split(",") if src.strip()]
        }

        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        with st.chat_message("assistant"):
            # ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
            st.write("ê²€ìƒ‰ ì¤‘...")
            response = create_response(question, keywords)
            st.markdown(response)

            # ì±„íŒ… ê¸°ë¡ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": response})

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

if __name__ == "__main__":
    main()
