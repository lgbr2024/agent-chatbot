import os
import re
import glob
from pinecone import Pinecone
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough
from langchain_pinecone import PineconeVectorStore
import streamlit as st
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import time

# Pinecone ë° API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["openai_api_key"]
os.environ["PINECONE_API_KEY"] = st.secrets["pinecone_api_key"]

# Pinecone ì»¤ìŠ¤í…€ ë²¡í„° ìŠ¤í† ì–´
class ModifiedPineconeVectorStore(PineconeVectorStore):
    def __init__(self, index, embedding, text_key: str = "text", namespace: str = ""):
        super().__init__(index, embedding, text_key, namespace)
        self.index = index
        self._embedding = embedding
        self._text_key = text_key
        self._namespace = namespace

    def similarity_search_with_score_by_vector(
        self, embedding: List[float], k: int = 8, filter: Dict[str, Any] = None, namespace: str = None
    ) -> List[Tuple[Document, float]]:
        namespace = namespace or self._namespace
        results = self.index.query(
            vector=embedding,
            top_k=k,
            include_metadata=True,
            filter=filter,
            namespace=namespace,
        )
        return [
            (
                Document(
                    page_content=result["metadata"].get(self._text_key, ""),
                    metadata={k: v for k, v in result["metadata"].items() if k != self._text_key}
                ),
                result["score"],
            )
            for result in results["matches"]
        ]

# Chatbot í”„ë¡¬í”„íŠ¸
chatbot_template = """
Question: {question}
Context: {context}
Answer:
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë©”íƒ€ë°ì´í„°ì˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
- ì£¼ì–´ì§„ ë¬¸ì„œì˜ ì¶œì²˜(source), í•µì‹¬ ë‚´ìš©(text), ê·¸ë¦¬ê³  ê´€ë ¨ëœ íƒœê·¸(tag_contents, tag_people, tag_company)ë¥¼ í™œìš©í•´ì„œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
- í•œêµ­ì–´ë¡œ ëŒ€í™”í˜• í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
chatbot_prompt = ChatPromptTemplate.from_template(chatbot_template)

def main():
    st.title("ğŸ“š Conference Q&A Chatbot")

    # Initialize session state
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Pinecone ì´ˆê¸°í™”
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index_name = "aiconference"
    index = pc.Index(index_name)

    # OpenAI ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o")
    vectorstore = ModifiedPineconeVectorStore(
        index=index,
        embedding=OpenAIEmbeddings(model="text-embedding-ada-002"),
        text_key="text"
    )

    # ê²€ìƒ‰ ì„¤ì •
    retriever = vectorstore.as_retriever(
        search_type='similarity',
        search_kwargs={"k": 10}
    )

    # ë¬¸ì„œ í¬ë§· í•¨ìˆ˜
    def format_docs(docs: List[Document]) -> str:
        formatted = []
        for doc in docs:
            source = doc.metadata.get('source', 'Unknown source')
            text = doc.page_content
            tags = ', '.join(
                f"{k}: {v}" for k, v in doc.metadata.items() if k.startswith("tag_")
            )
            formatted.append(f"ì¶œì²˜: {source}\níƒœê·¸: {tags}\në‚´ìš©: {text}")
        return "\n\n".join(formatted)

    format = itemgetter("docs") | RunnableLambda(format_docs)
    chain = RunnableParallel(question=RunnablePassthrough(), docs=retriever) | chatbot_prompt | llm | StrOutputParser()

    # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if question := st.chat_input("ì»¨í¼ëŸ°ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        with st.chat_message("assistant"):
            # ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
            st.write("ê²€ìƒ‰ ì¤‘...")
            response = chain.invoke({"question": question})
            st.markdown(response)

            # ì±„íŒ… ê¸°ë¡ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": response})

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

if __name__ == "__main__":
    main()
