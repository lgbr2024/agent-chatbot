import os
import re
import time
import streamlit as st
from typing import List, Tuple, Dict, Any
from pinecone import Pinecone
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_pinecone import PineconeVectorStore

# Pinecone ë° API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["openai_api_key"]
os.environ["PINECONE_API_KEY"] = st.secrets["pinecone_api_key"]

# Pinecone ì»¤ìŠ¤í…€ ë²¡í„° ìŠ¤í† ì–´
class ModifiedPineconeVectorStore(PineconeVectorStore):
    def __init__(self, index, embedding, text_key: str = "text", namespace: str = ""):
        super().__init__(index, embedding, text_key, namespace)
        self.index = index
        self._embedding = embedding
        self._text_key = text_key
        self._namespace = namespace

# Chatbot í”„ë¡¬í”„íŠ¸
chatbot_template = """
Question: {question}
Context: {context}
Answer:
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë©”íƒ€ë°ì´í„°ì˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
- ì£¼ì–´ì§„ ë¬¸ì„œì˜ ì¶œì²˜(source), í•µì‹¬ ë‚´ìš©(text), ê·¸ë¦¬ê³  ê´€ë ¨ëœ íƒœê·¸(tag_contents, tag_people, tag_company)ë¥¼ í™œìš©í•´ì„œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
- í•œêµ­ì–´ë¡œ ëŒ€í™”í˜• í†¤ìœ¼ë¡œ 2ì²œì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
- í•´ë‹¹ ë‚´ìš© ë¬¸ë‹¨ì˜ ëì—ëŠ” ì¶œì²˜, ë°œí‘œì ë‚´ìš©ì„ ê¼­ í‘œì‹œí•´ì£¼ì„¸ìš”.
"""
chatbot_prompt = ChatPromptTemplate.from_template(chatbot_template)

def main():
    st.title("ğŸ“š Agent Conference Q&A Chatbot")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Pinecone ì´ˆê¸°í™”
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index_name = "aiconference"
    index = pc.Index(index_name)

    # OpenAI ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o")
    vectorstore = ModifiedPineconeVectorStore(
        index=index,
        embedding=OpenAIEmbeddings(model="text-embedding-curie-001"),
        text_key="text"
    )

    
    
    # ê²€ìƒ‰ ì„¤ì •
    #retriever = vectorstore.as_retriever(
    #    search_type='similarity',
    #    search_kwargs={"k": 10}
    #)

    # ê²€ìƒ‰ ì„¤ì •
    retriever = vectorstore.as_retriever(
        search_type='similarity',
        search_kwargs={
            "k": 10,  # ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            "filter": None  # í•„í„° ì¶”ê°€
        }
    )
    
    def create_retriever_with_filter(keywords: Dict[str, Any]) -> ModifiedPineconeVectorStore:
        """
        ê²€ìƒ‰ í•„í„°ë¥¼ ì ìš©í•˜ì—¬ retrieverë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    
        :param keywords: ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œ ë° ê²€ìƒ‰ ì¡°ê±´ (íƒœê·¸, ì¶œì²˜ ë“±)
        :return: í•„í„°ê°€ ì ìš©ëœ retriever ê°ì²´
        """
        # ì‚¬ìš©ì í‚¤ì›Œë“œì—ì„œ í•„í„° ì¡°ê±´ ìƒì„±
        filter_conditions = {}
        
        # íƒœê·¸ í•„í„° ì¶”ê°€
        if "tag_contents" in keywords:
            filter_conditions["tag_contents"] = {"$in": keywords["tag_contents"]}  # íƒœê·¸ ëª©ë¡
        if "tag_people" in keywords:
            filter_conditions["tag_people"] = {"$in": keywords["tag_people"]}
        if "tag_company" in keywords:
            filter_conditions["tag_company"] = {"$in": keywords["tag_company"]}
        
        # ì¶œì²˜ í•„í„° ì¶”ê°€
        if "source" in keywords:
            filter_conditions["source"] = {"$in": keywords["source"]}
    
        # retriever ê°ì²´ ìƒì„±
        return vectorstore.as_retriever(
            search_type='similarity',
            search_kwargs={
                "k": 10,
                "filter": filter_conditions
            }
        )


    # ë¬¸ì„œ í¬ë§· í•¨ìˆ˜
    def format_docs(docs: List[Document]) -> str:
        formatted = []
        for doc in docs:
            source = doc.metadata.get('source', 'Unknown source')
            text = doc.page_content
            tags = ', '.join(
                f"{k}: {v}" for k, v in doc.metadata.items() if k.startswith("tag_")
            )
            formatted.append(f"ì¶œì²˜: {source}\níƒœê·¸: {tags}\në‚´ìš©: {text}")
        return "\n\n".join(formatted)

    # ë¬¸ì„œì™€ í”„ë¡¬í”„íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ë‹µë³€ ìƒì„±
    def create_response(question: str) -> str:
        # ê²€ìƒ‰ëœ ë¬¸ì„œ í¬ë§·íŒ…
        docs = retriever.invoke(question)
        context = format_docs(docs)

        # í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ ë°ì´í„° ìƒì„±
        prompt_input = {"question": question, "context": context}
        prompt = chatbot_prompt.invoke(prompt_input)

        # LLM í˜¸ì¶œ ë° ê²°ê³¼ ë°˜í™˜
        llm_response = llm.invoke(prompt)
        return StrOutputParser().invoke(llm_response)

    # ì´ì „ ëŒ€í™” í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if question := st.chat_input("ì»¨í¼ëŸ°ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        with st.chat_message("assistant"):
            # ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
            st.write("ê²€ìƒ‰ ì¤‘...")
            response = create_response(question)
            st.markdown(response)

            # ì±„íŒ… ê¸°ë¡ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": response})

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

if __name__ == "__main__":
    main()
